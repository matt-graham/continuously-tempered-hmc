{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['THEANO_FLAGS'] = 'device=gpu0,floatX=float32'\n",
    "import pprint as pp\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import theano as th\n",
    "import theano.tensor as tt\n",
    "import theano.sandbox.rng_mrg as rand\n",
    "import theano.tensor.slinalg as sla\n",
    "import matplotlib.pyplot as plt\n",
    "import thermomc.continuous_temp as cont_temp\n",
    "import thermomc.discrete_temp as disc_temp\n",
    "import thermomc.control_funcs as ctrl\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.getcwd())\n",
    "model_dir = os.path.join(base_dir, 'data', 'omni-iwae')\n",
    "exp_dir = os.path.join(base_dir, 'experiments', 'omni-iwae')\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 201703\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder = np.load(os.path.join(model_dir, 'decoder_params.npz'))\n",
    "encoder_h = np.load(os.path.join(model_dir, 'encoder_h_params.npz'))\n",
    "encoder_mean = np.load(os.path.join(model_dir, 'encoder_mean_params.npz'))\n",
    "encoder_std = np.load(os.path.join(model_dir, 'encoder_std_params.npz'))\n",
    "samples_and_log_norm_bounds = np.load(os.path.join(model_dir, 'joint-sample-and-log-norm-bounds.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = samples_and_log_norm_bounds['xs']\n",
    "var_mean_z_gvn_x = samples_and_log_norm_bounds['mean_z_gvn_x']\n",
    "var_std_z_gvn_x = samples_and_log_norm_bounds['std_z_gvn_x']\n",
    "log_zeta = samples_and_log_norm_bounds['log_zeta']\n",
    "log_norm_lower = samples_and_log_norm_bounds['log_norm_lower']\n",
    "log_norm_upper = samples_and_log_norm_bounds['log_norm_upper']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def sigmoidal_schedule(num_temp, scale):\n",
    "    inv_temp_sched = sigmoid(\n",
    "        scale * (2. * np.arange(num_temp + 1) / num_temp - 1.))\n",
    "    return (\n",
    "        (inv_temp_sched - inv_temp_sched[0]) / \n",
    "        (inv_temp_sched[-1] - inv_temp_sched[0])\n",
    "    )\n",
    "\n",
    "def rmse(x, y):\n",
    "    return ((x - y)**2).mean()**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhiFunc(object):\n",
    "    \n",
    "    def __init__(self, x, weights, biases, non_linearities, log_zeta, var_mean, var_std):\n",
    "        self.x = x\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "        self.non_linearities = non_linearities\n",
    "        self.log_zeta = log_zeta\n",
    "        self.var_mean = var_mean\n",
    "        self.var_std = var_std\n",
    "        \n",
    "    def mean_x_gvn_z(self, z):\n",
    "        h = z\n",
    "        for W, b, f in zip(self.weights, self.biases, self.non_linearities):\n",
    "            h = f(h.dot(W) + b)\n",
    "        return h\n",
    "        \n",
    "    def __call__(self, u):\n",
    "        z = u * self.var_std + self.var_mean\n",
    "        mean = self.mean_x_gvn_z(z)\n",
    "        return (\n",
    "            0.5 * (z**2).sum(-1) + 0.5 * z.shape[-1] * tt.log(2 * np.pi) -\n",
    "            (self.x * tt.log(mean) + (1 - self.x) * tt.log(1 - mean)).sum(-1) +\n",
    "            self.log_zeta - tt.log(self.var_std).sum(-1)\n",
    "        )\n",
    "\n",
    "class PsiFunc(object):\n",
    "    \n",
    "    def __call__(self, u):\n",
    "        return (\n",
    "            0.5 * (u**2).sum(-1) +  0.5 * u.shape[-1] * tt.log(2 * np.pi)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_linearity_map = {\n",
    "    'nnet.Tanh': tt.tanh,\n",
    "    'nnet.Sigmoid': tt.nnet.sigmoid,\n",
    "    'nnet.Exp': tt.exp\n",
    "}\n",
    "non_linearities = [\n",
    "    non_linearity_map[name] \n",
    "    for name in decoder['layers'] if name != 'nnet.Linear'\n",
    "]\n",
    "weights = [\n",
    "    tt.constant(decoder['W' + str(i * 2)], 'dec_W' + str(i), \n",
    "                2, dtype=th.config.floatX) \n",
    "    for i in range(3)\n",
    "]\n",
    "biases = [\n",
    "    tt.constant(decoder['b' + str(i * 2)], 'dec_b' + str(i), \n",
    "                2, dtype=th.config.floatX) \n",
    "    for i in range(3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "num_data = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annealed Importance Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_temps = [50, 100, 200, 500, 1000, 2000]\n",
    "temp_scale = 4.\n",
    "dt = 0.4\n",
    "num_step = 10\n",
    "mom_resample_coeff = 1.\n",
    "num_runs = 16\n",
    "num_reps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmc_params = {\n",
    "    'dt': dt,\n",
    "    'n_step': num_step,\n",
    "    'mom_resample_coeff': mom_resample_coeff\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create repeated model parameters / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_zeta_rep = tt.constant(\n",
    "    log_zeta.repeat(num_runs), 'log_zeta', 1, th.config.floatX) \n",
    "x_rep = tt.constant(\n",
    "    x.repeat(num_runs, 0), 'x', 2, th.config.floatX)\n",
    "var_mean_z_gvn_x_rep = tt.constant(\n",
    "    var_mean_z_gvn_x.repeat(num_runs, 0), 'var_mean_z_gvn_x', 2, th.config.floatX)\n",
    "var_std_z_gvn_x_rep = tt.constant(\n",
    "    var_std_z_gvn_x.repeat(num_runs, 0), 'var_std_z_gvn_x', 2, th.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_func = PhiFunc(\n",
    "    x_rep, weights, biases, non_linearities, log_zeta_rep,\n",
    "    var_mean_z_gvn_x_rep, var_std_z_gvn_x_rep)\n",
    "psi_func = PsiFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ais_sampler = disc_temp.AnnealedImportanceSampler(\n",
    "   rand.MRG_RandomStreams(seed), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = tt.matrix('pos')\n",
    "inv_temps= tt.vector('inv_temp_sched')\n",
    "pos_samples, log_weights, accepts, updates = ais_sampler.run(\n",
    "    pos, None, inv_temps, phi_func, psi_func, hmc_params\n",
    ")\n",
    "ais_run = th.function(\n",
    "    [pos, inv_temps],\n",
    "    [log_weights, accepts],\n",
    "    updates=updates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIS runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng.seed(seed)\n",
    "ais_sampler.srng.seed(seed)\n",
    "ais_settings = {\n",
    "    'dt': dt,\n",
    "    'num_temps': num_temps,\n",
    "    'temp_scale': temp_scale,\n",
    "    'num_step': num_step,\n",
    "    'mom_resample_coeff': mom_resample_coeff,\n",
    "    'num_runs': num_runs,\n",
    "}\n",
    "print('-' * 100)\n",
    "pp.pprint(ais_settings)\n",
    "print('-' * 100)\n",
    "settings_path = os.path.join(exp_dir, 'ais-settings.json')\n",
    "results_path = os.path.join(exp_dir, 'ais-results.npz')\n",
    "with open(settings_path, 'w') as f:\n",
    "        json.dump(ais_settings, f, indent=True)\n",
    "ais_sampling_times = np.empty((num_reps, len(num_temps))) * np.nan\n",
    "ais_log_norm_ests = np.empty((num_reps, len(num_temps))) * np.nan\n",
    "for i in range(num_reps):\n",
    "    print('Repeat {0}'.format(i + 1))\n",
    "    print('-' * 100)\n",
    "    for t, num_temp in enumerate(num_temps):\n",
    "        print('Num temps {0}'.format(num_temp))\n",
    "        print('-' * 100)\n",
    "        inv_temp_sched = sigmoidal_schedule(num_temp, temp_scale)\n",
    "        pos_init = rng.normal(size=(num_runs * num_data, latent_dim))\n",
    "        start_time = time.time()\n",
    "        log_weights, accepts = ais_run(\n",
    "            pos_init.astype(th.config.floatX), inv_temp_sched.astype(th.config.floatX))\n",
    "        ais_sampling_times[i, t] = time.time() - start_time\n",
    "        print('Sampling time: {0:.2f}s'.format(ais_sampling_times[i, t]))\n",
    "        print('Accept: mean={0:.2f} min={1:.2f} max={2:.2f}'\n",
    "              .format(accepts.mean(), accepts.min(), accepts.max()))\n",
    "        ais_log_norm_ests[i, t] = log_zeta.mean() + np.log(\n",
    "            np.exp(log_weights.reshape((-1, num_runs))).mean(-1)).mean(0)\n",
    "        print('Log norm est={0:.2f}').format(ais_log_norm_ests[i, t])\n",
    "        print('-' * 100)\n",
    "np.savez(\n",
    "    results_path, \n",
    "    sampling_times=ais_sampling_times, \n",
    "    log_norm_ests=ais_log_norm_ests,\n",
    ")\n",
    "print('Saved to ' + results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(num_reps):\n",
    "    ax.plot(ais_sampling_times[i, :], ais_log_norm_ests[i, :], 'ro')\n",
    "ax.plot([0, ais_sampling_times[:, -1].mean()], [log_norm_upper, log_norm_upper], 'k--')\n",
    "ax.plot([0, ais_sampling_times[:, -1].mean()], [log_norm_lower, log_norm_lower], 'k--')\n",
    "ax.set_xlabel('Time / s')\n",
    "ax.set_ylabel('$\\\\log Z$ estimate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated tempering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = 0.4\n",
    "num_temp = 1000\n",
    "num_step = 10\n",
    "mom_resample_coeff = 1.\n",
    "temp_scale = 4.\n",
    "num_runs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmc_params = {\n",
    "    'dt': dt,\n",
    "    'n_step': num_step,\n",
    "    'mom_resample_coeff': mom_resample_coeff\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_zeta_rep = tt.constant(\n",
    "    log_zeta.repeat(num_runs), 'log_zeta', 1, th.config.floatX) \n",
    "x_rep = tt.constant(\n",
    "    x.repeat(num_runs, 0), 'x', 2, th.config.floatX)\n",
    "var_mean_z_gvn_x_rep = tt.constant(\n",
    "    var_mean_z_gvn_x.repeat(num_runs, 0), 'var_mean_z_gvn_x', 2, th.config.floatX)\n",
    "var_std_z_gvn_x_rep = tt.constant(\n",
    "    var_std_z_gvn_x.repeat(num_runs, 0), 'var_std_z_gvn_x', 2, th.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_func = PhiFunc(\n",
    "    x_rep, weights, biases, non_linearities, log_zeta_rep,\n",
    "    var_mean_z_gvn_x_rep, var_std_z_gvn_x_rep\n",
    ")\n",
    "psi_func = PsiFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = tt.matrix('pos')\n",
    "idx = tt.lvector('idx')\n",
    "inv_temps = tt.vector('inv_temps')\n",
    "num_sample = tt.lscalar('num_sample')\n",
    "st_sampler = disc_temp.SimulatedTemperingSampler(\n",
    "    rand.MRG_RandomStreams(seed), False\n",
    ")\n",
    "pos_samples, idx_samples, probs_0, probs_1, accepts, updates = st_sampler.chain(\n",
    "    pos, None, idx, inv_temps, 0, phi_func, psi_func, num_sample, hmc_params\n",
    ")\n",
    "st_chain = th.function(\n",
    "    [pos, idx, inv_temps, num_sample],\n",
    "    [probs_0, probs_1, accepts],\n",
    "    updates=updates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ST runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sample = 3000\n",
    "num_warm_up = 0\n",
    "num_data = 1000\n",
    "num_reps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng.seed(seed)\n",
    "st_sampler.srng.seed(seed)\n",
    "st_settings = {\n",
    "    'dt': dt,\n",
    "    'num_step': num_step,\n",
    "    'mom_resample_coeff': mom_resample_coeff,\n",
    "    'num_warmup': num_warm_up,\n",
    "    'temp_scale': temp_scale,\n",
    "    'num_temp': num_temp,\n",
    "    'num_runs': num_runs,\n",
    "}\n",
    "inv_temp_sched = sigmoidal_schedule(num_temp, temp_scale)\n",
    "print('-' * 100)\n",
    "pp.pprint(st_settings)\n",
    "print('-' * 100)\n",
    "settings_path = os.path.join(exp_dir, 'st-settings.json')\n",
    "with open(settings_path, 'w') as f:\n",
    "    json.dump(st_settings, f, indent=True)\n",
    "results_path = os.path.join(exp_dir, 'st-results.npz')\n",
    "st_log_norm_ests = np.empty((num_reps, num_sample - num_warm_up)) * np.nan\n",
    "st_sampling_times = np.empty(num_reps) * np.nan\n",
    "for i in range(num_reps):\n",
    "    print('Repeat {0}'.format(i + 1))\n",
    "    pos_init = rng.normal(size=(num_runs * num_data, latent_dim))\n",
    "    idx_init = rng.randint(low=0, high=num_temp, size=num_runs * x.shape[0])\n",
    "    start_time = time.time()\n",
    "    probs_0, probs_1, accepts = st_chain(\n",
    "        pos_init.astype(th.config.floatX), \n",
    "        idx_init,\n",
    "        inv_temp_sched.astype(th.config.floatX),\n",
    "        num_sample\n",
    "    )\n",
    "    st_sampling_times[i] = time.time() - start_time\n",
    "    st_log_norm_ests[i] = (\n",
    "        log_zeta.mean() + \n",
    "        np.log(probs_1[num_warm_up:].reshape((-1, 1000, num_runs)).mean(-1).cumsum(0)) - \n",
    "        np.log(probs_0[num_warm_up:].reshape((-1, 1000, num_runs)).mean(-1).cumsum(0))\n",
    "    ).mean(1)\n",
    "    print('Sampling time: {0:.2f}s'.format(st_sampling_times[i]))\n",
    "    print('Accept: mean={0:.2f} min={1:.2f} max={2:.2f}'\n",
    "          .format(accepts.mean(), accepts.min(), accepts.max()))\n",
    "    print('Log norm est={0:.2f}'.format(st_log_norm_ests[i][-1]))\n",
    "    print('-' * 100)\n",
    "np.savez(\n",
    "    results_path, \n",
    "    sampling_times=st_sampling_times,  \n",
    "    log_norm_ests=st_log_norm_ests,\n",
    ")\n",
    "print('Saved to ' + results_path)\n",
    "print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Log norm est final mean={0:.4f}'.format(st_log_norm_ests[:, -1].mean()))\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(num_reps):\n",
    "    ax.plot(np.arange(num_warm_up, num_sample) * \n",
    "            st_sampling_times[i] / num_sample, st_log_norm_ests[i])\n",
    "ax.plot([0, st_sampling_times.mean()], [log_norm_upper, log_norm_upper], 'k--')\n",
    "ax.plot([0, st_sampling_times.mean()], [log_norm_lower, log_norm_lower], 'k--')\n",
    "ax.set_xlabel('Time / s')\n",
    "ax.set_ylabel('$\\\\log Z$ estimate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs continuous tempering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = 0.4\n",
    "num_step = 10\n",
    "mom_resample_coeff = 1.\n",
    "num_runs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmc_params = {\n",
    "    'dt': dt,\n",
    "    'n_step': num_step,\n",
    "    'mom_resample_coeff': mom_resample_coeff\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_zeta_rep = tt.constant(\n",
    "    log_zeta.repeat(num_runs), 'log_zeta', 1, th.config.floatX) \n",
    "x_rep = tt.constant(\n",
    "    x.repeat(num_runs, 0), 'x', 2, th.config.floatX)\n",
    "var_mean_z_gvn_x_rep = tt.constant(\n",
    "    var_mean_z_gvn_x.repeat(num_runs, 0), 'var_mean_z_gvn_x', 2, th.config.floatX)\n",
    "var_std_z_gvn_x_rep = tt.constant(\n",
    "    var_std_z_gvn_x.repeat(num_runs, 0), 'var_std_z_gvn_x', 2, th.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_func = PhiFunc(\n",
    "    x_rep, weights, biases, non_linearities, log_zeta_rep,\n",
    "    var_mean_z_gvn_x_rep, var_std_z_gvn_x_rep\n",
    ")\n",
    "psi_func = PsiFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = tt.matrix('pos')\n",
    "inv_temp = tt.vector('inv_temp')\n",
    "num_sample = tt.lscalar('n_sample')\n",
    "gct_sampler = cont_temp.GibbsContinuousTemperingSampler(\n",
    "    rand.MRG_RandomStreams(seed), False\n",
    ")\n",
    "pos_samples, inv_temp_samples, probs_0, probs_1, accepts, updates = gct_sampler.chain(\n",
    "    pos, None, inv_temp, phi_func, psi_func, num_sample, hmc_params\n",
    ")\n",
    "gct_chain = th.function(\n",
    "    [pos, inv_temp, num_sample],\n",
    "    [probs_0, probs_1, accepts],\n",
    "    updates=updates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs CT runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sample = 10000\n",
    "num_warm_up = 0\n",
    "num_data = 1000\n",
    "num_reps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng.seed(seed)\n",
    "gct_sampler.srng.seed(seed)\n",
    "gct_settings = {\n",
    "    'dt': dt,\n",
    "    'num_step': num_step,\n",
    "    'mom_resample_coeff': mom_resample_coeff,\n",
    "    'num_warmup': num_warm_up,\n",
    "    'num_runs': num_runs,\n",
    "}\n",
    "print('-' * 100)\n",
    "pp.pprint(gct_settings)\n",
    "print('-' * 100)\n",
    "settings_path = os.path.join(exp_dir, 'gct-settings.json')\n",
    "with open(settings_path, 'w') as f:\n",
    "    json.dump(gct_settings, f, indent=True)\n",
    "results_path = os.path.join(exp_dir, 'gct-results.npz')\n",
    "gct_log_norm_ests = np.empty((num_reps, num_sample - num_warm_up)) * np.nan\n",
    "gct_sampling_times = np.empty(num_reps) * np.nan\n",
    "for i in range(num_reps):\n",
    "    print('Repeat {0}'.format(i + 1))\n",
    "    pos_init = rng.normal(size=(num_runs * num_data, latent_dim))\n",
    "    inv_temp_init = sigmoid(rng.normal(size=num_runs * x.shape[0]))\n",
    "    start_time = time.time()\n",
    "    probs_0, probs_1, accepts = gct_chain(\n",
    "        pos_init.astype(th.config.floatX), \n",
    "        inv_temp_init.astype(th.config.floatX), \n",
    "        num_sample\n",
    "    )\n",
    "    gct_sampling_times[i] = time.time() - start_time\n",
    "    gct_log_norm_ests[i] = (\n",
    "        log_zeta.mean() + \n",
    "        np.log(probs_1[num_warm_up:].reshape((-1, 1000, num_runs)).mean(-1).cumsum(0)) - \n",
    "        np.log(probs_0[num_warm_up:].reshape((-1, 1000, num_runs)).mean(-1).cumsum(0))\n",
    "    ).mean(1)\n",
    "    print('Sampling time: {0:.2f}s'.format(gct_sampling_times[i]))\n",
    "    print('Accept: mean={0:.2f} min={1:.2f} max={2:.2f}'\n",
    "          .format(accepts.mean(), accepts.min(), accepts.max()))\n",
    "    print('Log norm est={0:.2f}'.format(gct_log_norm_ests[i][-1]))\n",
    "    print('-' * 100)\n",
    "np.savez(\n",
    "    results_path, \n",
    "    sampling_times=gct_sampling_times,  \n",
    "    log_norm_ests=gct_log_norm_ests,\n",
    ")\n",
    "print('Saved to ' + results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Log norm est final mean={0:.4f}'.format(gct_log_norm_ests[:, -1].mean()))\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(num_reps):\n",
    "    ax.plot(np.arange(num_warm_up, num_sample) * \n",
    "            gct_sampling_times[i] / num_sample, gct_log_norm_ests[i])\n",
    "ax.plot([0, gct_sampling_times.mean()], [log_norm_upper, log_norm_upper], 'k--')\n",
    "ax.plot([0, gct_sampling_times.mean()], [log_norm_lower, log_norm_lower], 'k--')\n",
    "ax.set_xlabel('Time / s')\n",
    "ax.set_ylabel('$\\\\log Z$ estimate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint continuous tempering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = 0.4\n",
    "num_step = 10\n",
    "temp_scale = 5.\n",
    "mom_resample_coeff = 1.\n",
    "num_runs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmc_params = {\n",
    "    'dt': dt,\n",
    "    'n_step': num_step,\n",
    "    'mom_resample_coeff': mom_resample_coeff\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_zeta_rep = tt.constant(\n",
    "    log_zeta.repeat(num_runs), 'log_zeta', 1, th.config.floatX) \n",
    "x_rep = tt.constant(\n",
    "    x.repeat(num_runs, 0), 'x', 2, th.config.floatX)\n",
    "var_mean_z_gvn_x_rep = tt.constant(\n",
    "    var_mean_z_gvn_x.repeat(num_runs, 0), 'var_mean_z_gvn_x', 2, th.config.floatX)\n",
    "var_std_z_gvn_x_rep = tt.constant(\n",
    "    var_std_z_gvn_x.repeat(num_runs, 0), 'var_std_z_gvn_x', 2, th.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi_func = PhiFunc(\n",
    "    x_rep, weights, biases, non_linearities, log_zeta_rep,\n",
    "    var_mean_z_gvn_x_rep, var_std_z_gvn_x_rep\n",
    ")\n",
    "psi_func = PsiFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = tt.matrix('pos')\n",
    "tmp_ctrl = tt.vector('tmp_ctrl')\n",
    "num_sample = tt.lscalar('n_sample')\n",
    "ctrl_func = ctrl.SigmoidalControlFunction(temp_scale)\n",
    "hmc_params = {\n",
    "    'dt': dt,\n",
    "    'n_step': num_step,\n",
    "    'mom_resample_coeff': mom_resample_coeff\n",
    "}\n",
    "jct_sampler = cont_temp.JointContinuousTemperingSampler(\n",
    "    rand.MRG_RandomStreams(seed), False\n",
    ")\n",
    "(pos_samples, tmp_ctrl_samples, inv_temp_samples, \n",
    " probs_0, probs_1, accepts, updates) = jct_sampler.chain(\n",
    "    pos, tmp_ctrl, None, phi_func, psi_func, ctrl_func, num_sample, hmc_params\n",
    ")\n",
    "jct_chain = th.function(\n",
    "    [pos, tmp_ctrl, num_sample],\n",
    "    [probs_0, probs_1, accepts],\n",
    "    updates=updates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint CT runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_sample = 7500\n",
    "num_warm_up = 0\n",
    "num_data = 1000\n",
    "num_reps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng.seed(seed)\n",
    "jct_sampler.srng.seed(seed)\n",
    "jct_settings = {\n",
    "    'dt': dt,\n",
    "    'num_step': num_step,\n",
    "    'mom_resample_coeff': mom_resample_coeff,\n",
    "    'num_warmup': num_warm_up,\n",
    "    'temp_scale': temp_scale,\n",
    "    'num_runs': num_runs,\n",
    "}\n",
    "print('-' * 100)\n",
    "pp.pprint(jct_settings)\n",
    "print('-' * 100)\n",
    "settings_path = os.path.join(exp_dir, 'jct-settings.json')\n",
    "with open(settings_path, 'w') as f:\n",
    "    json.dump(jct_settings, f, indent=True)\n",
    "results_path = os.path.join(exp_dir, 'jct-results.npz')\n",
    "jct_log_norm_ests = np.empty((num_reps, num_sample - num_warm_up)) * np.nan\n",
    "jct_sampling_times = np.empty(num_reps) * np.nan\n",
    "for i in range(num_reps):\n",
    "    print('Repeat {0}'.format(i + 1))\n",
    "    pos_init = rng.normal(size=(num_runs * num_data, latent_dim))\n",
    "    tmp_ctrl_init = rng.normal(size=num_runs * x.shape[0]) * temp_scale\n",
    "    start_time = time.time()\n",
    "    probs_0, probs_1, accepts = jct_chain(\n",
    "        pos_init.astype(th.config.floatX), \n",
    "        tmp_ctrl_init.astype(th.config.floatX), \n",
    "        num_sample\n",
    "    )\n",
    "    jct_sampling_times[i] = time.time() - start_time\n",
    "    jct_log_norm_ests[i] = (\n",
    "        log_zeta.mean() + \n",
    "        np.log(probs_1[num_warm_up:].reshape((-1, 1000, num_runs)).mean(-1).cumsum(0)) - \n",
    "        np.log(probs_0[num_warm_up:].reshape((-1, 1000, num_runs)).mean(-1).cumsum(0))\n",
    "    ).mean(1)\n",
    "    print('Sampling time: {0:.2f}s'.format(jct_sampling_times[i]))\n",
    "    print('Accept: mean={0:.2f} min={1:.2f} max={2:.2f}'\n",
    "          .format(accepts.mean(), accepts.min(), accepts.max()))\n",
    "    print('Log norm est={0:.2f}'.format(jct_log_norm_ests[i][-1]))\n",
    "    print('-' * 100)\n",
    "np.savez(\n",
    "    results_path, \n",
    "    sampling_times=jct_sampling_times,  \n",
    "    log_norm_ests=jct_log_norm_ests,\n",
    ")\n",
    "print('Saved to ' + results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Log norm est final mean={0:.4f}'.format(jct_log_norm_ests[:, -1].mean()))\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(num_reps):\n",
    "    ax.plot(np.arange(num_warm_up, num_sample) * \n",
    "            jct_sampling_times[i] / num_sample, jct_log_norm_ests[i])\n",
    "ax.plot([0, jct_sampling_times.mean()], [log_norm_upper, log_norm_upper], 'k--')\n",
    "ax.plot([0, jct_sampling_times.mean()], [log_norm_lower, log_norm_lower], 'k--')\n",
    "ax.set_xlabel('Time / s')\n",
    "ax.set_ylabel('$\\\\log Z$ estimate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(ais_sampling_times.shape[0]):\n",
    "    ax.plot(ais_sampling_times[i], ais_log_norm_ests[i], 'ro')\n",
    "for i in range(st_sampling_times.shape[0]):\n",
    "    ax.plot(np.arange(st_settings['num_warmup'], st_log_norm_ests.shape[1]) * \n",
    "            st_sampling_times[i] / st_log_norm_ests.shape[1], st_log_norm_ests[i], 'g-')\n",
    "for i in range(gct_sampling_times.shape[0]):\n",
    "    ax.plot(np.arange(gct_settings['num_warmup'], gct_log_norm_ests.shape[1]) * \n",
    "            gct_sampling_times[i] / gct_log_norm_ests.shape[1], gct_log_norm_ests[i], 'b-')\n",
    "for i in range(jct_sampling_times.shape[0]):\n",
    "    ax.plot(np.arange(gct_settings['num_warmup'], jct_log_norm_ests.shape[1]) * \n",
    "            jct_sampling_times[i] / jct_log_norm_ests.shape[1], jct_log_norm_ests[i], 'c-')\n",
    "ax.plot([0, 350], [log_norm_upper, log_norm_upper], 'k--')\n",
    "ax.plot([0, 350], [log_norm_lower, log_norm_lower], 'k--')\n",
    "ax.set_xlabel('Time / s')\n",
    "ax.set_ylabel('$\\\\log Z$ estimate')\n",
    "#ax.set_ylim(-110.2, -109.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(ais_sampling_times.mean(0), ais_log_norm_ests.mean(0), 'ro')\n",
    "ax.plot(np.arange(st_settings['num_warmup'], st_log_norm_ests.shape[1]) * \n",
    "        st_sampling_times.mean(0) / st_log_norm_ests.shape[1], \n",
    "        st_log_norm_ests.mean(0), 'g-')\n",
    "ax.plot(np.arange(gct_settings['num_warmup'], gct_log_norm_ests.shape[1]) * \n",
    "        gct_sampling_times.mean(0) / gct_log_norm_ests.shape[1], \n",
    "        gct_log_norm_ests.mean(0), 'b-')\n",
    "ax.plot(np.arange(jct_settings['num_warmup'], jct_log_norm_ests.shape[1]) * \n",
    "        jct_sampling_times.mean(0) / jct_log_norm_ests.shape[1], \n",
    "        jct_log_norm_ests.mean(0), 'c-')\n",
    "ax.plot([0, 350], [log_norm_upper, log_norm_upper], 'k--')\n",
    "ax.plot([0, 350], [log_norm_lower, log_norm_lower], 'k--')\n",
    "ax.set_xlabel('Time / s')\n",
    "ax.set_ylabel('$\\\\log Z$ estimate')\n",
    "#ax.set_ylim(-110.8, -109.8)\n",
    "ax.set_xlim(0, 350)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "im_grid = np.zeros((700, 1120))\n",
    "for i, im in enumerate(x[:]):\n",
    "    row = i % 25\n",
    "    col = i // 25\n",
    "    im_grid[row * 28 : (row + 1) * 28, col * 28 : (col + 1) * 28] = (\n",
    "        im.reshape(28, 28)\n",
    "    )\n",
    "ax.imshow(im_grid, cmap='Greys', interpolation='None')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_frame_on(False)\n",
    "fig.tight_layout(pad=0)\n",
    "fig.savefig(os.path.join(exp_dir, 'omni-samples.pdf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
