{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['THEANO_FLAGS'] = 'device=gpu0,floatX=float32'\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import theano as th\n",
    "import theano.tensor as tt\n",
    "import theano.d3viz as d3v\n",
    "import theano.sandbox.rng_mrg as rand\n",
    "import thermomc.discrete_temp as disc_temp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.getcwd())\n",
    "model_dir = os.path.join(base_dir, 'data', 'omni-iwae')\n",
    "decoder = np.load(os.path.join(model_dir, 'decoder_params.npz'))\n",
    "encoder_h = np.load(os.path.join(model_dir, 'encoder_h_params.npz'))\n",
    "encoder_mean = np.load(os.path.join(model_dir, 'encoder_mean_params.npz'))\n",
    "encoder_std = np.load(os.path.join(model_dir, 'encoder_std_params.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def sigmoidal_schedule(num_temp, scale):\n",
    "    inv_temp_sched = sigmoid(\n",
    "        scale * (2. * np.arange(num_temp + 1) / num_temp - 1.))\n",
    "    return (\n",
    "        (inv_temp_sched - inv_temp_sched[0]) / \n",
    "        (inv_temp_sched[-1] - inv_temp_sched[0])\n",
    "    )\n",
    "\n",
    "def rmse(x, y):\n",
    "    return ((x - y)**2).mean()**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_linearity_map_np = {\n",
    "    'nnet.Tanh': np.tanh,\n",
    "    'nnet.Sigmoid': sigmoid,\n",
    "    'nnet.Exponential': np.exp\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_x_gvn_z_np(z):\n",
    "    h = z\n",
    "    for i, layer in enumerate(decoder['layers']):\n",
    "        if layer == 'nnet.Linear':\n",
    "            W = decoder['W' + str(i)]\n",
    "            b = decoder['b' + str(i)]\n",
    "            h = h.dot(W) + b\n",
    "        else:\n",
    "            h = non_linearity_map_np[layer](h)\n",
    "    return h\n",
    "\n",
    "def mean_and_std_z_gvn_x_np(x):\n",
    "    h = x\n",
    "    for i, layer in enumerate(encoder_h['layers']):\n",
    "        if layer == 'nnet.Linear':\n",
    "            W = encoder_h['W' + str(i)]\n",
    "            b = encoder_h['b' + str(i)]\n",
    "            h = h.dot(W) + b\n",
    "        else:\n",
    "            h = non_linearity_map_np[layer](h)\n",
    "    std = h * 1.\n",
    "    for i, layer in enumerate(encoder_std['layers']):\n",
    "        if layer == 'nnet.Linear':\n",
    "            W = encoder_std['W' + str(i)]\n",
    "            b = encoder_std['b' + str(i)]\n",
    "            std = std.dot(W) + b\n",
    "        else:\n",
    "            std = non_linearity_map_np[layer](std)\n",
    "    mean = h * 1.\n",
    "    for i, layer in enumerate(encoder_mean['layers']):\n",
    "        if layer == 'nnet.Linear':\n",
    "            W = encoder_mean['W' + str(i)]\n",
    "            b = encoder_mean['b' + str(i)]\n",
    "            mean = mean.dot(W) + b\n",
    "        else:\n",
    "            mean = non_linearity_map_np[layer](mean)\n",
    "    return mean, std\n",
    "\n",
    "def log_prob_x_gvn_z_np(x, z):\n",
    "    means = mean_x_gvn_z_np(z)\n",
    "    return (x * np.log(means) + (1 - x) * np.log(1 - means)).sum(-1)\n",
    "\n",
    "def log_prob_z_np(z):\n",
    "    return -0.5 * (z**2).sum(-1) - 0.5 * z.shape[-1] * np.log(2 * np.pi)\n",
    "\n",
    "def log_prob_x_and_z_np(x, z):\n",
    "    return log_prob_x_gvn_z_np(x, z) + log_prob_z_np(z)\n",
    "\n",
    "def log_prob_z_gvn_x_np(x, z, means=None, stds=None):\n",
    "    if means is None or stds is None:\n",
    "        means, stds = mean_and_std_z_gvn_x(x)\n",
    "    return -(\n",
    "        0.5 * ((z - means)**2 / stds**2).sum(-1) +\n",
    "        0.5 * z.shape[-1] * np.log(2 * np.pi) +\n",
    "        np.log(stds).sum(-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhiFunc(object):\n",
    "    \n",
    "    def __init__(self, x, weights, biases, non_linearities, log_zeta):\n",
    "        self.x = x\n",
    "        self.weights = weights\n",
    "        self.biases = biases\n",
    "        self.non_linearities = non_linearities\n",
    "        self.log_zeta = log_zeta\n",
    "        \n",
    "    def mean_x_gvn_z(self, z):\n",
    "        h = z\n",
    "        for W, b, f in zip(self.weights, self.biases, self.non_linearities):\n",
    "            h = f(h.dot(W) + b)\n",
    "        return h\n",
    "        \n",
    "    def __call__(self, z):\n",
    "        mean = self.mean_x_gvn_z(z)\n",
    "        return (\n",
    "            0.5 * (z**2).sum(-1) + 0.5 * z.shape[-1] * tt.log(2 * np.pi) -\n",
    "            (self.x * tt.log(mean) + (1 - self.x) * tt.log(1 - mean)).sum(-1) +\n",
    "            self.log_zeta\n",
    "        )\n",
    "\n",
    "class PsiFunc(object):\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, z):\n",
    "        return (\n",
    "            0.5 * (((z - self.mean) / (self.std))**2).sum(-1) + \n",
    "            0.5 * self.mean.shape[-1] * tt.log(2 * np.pi) +\n",
    "            tt.log(self.std).sum(-1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $\\mathbf{x},\\,\\mathbf{z}$ pair from joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 201702\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 50\n",
    "n_samples = 1000\n",
    "n_reps = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zs = rng.normal(size=(n_samples, latent_dim))\n",
    "means = mean_x_gvn_z_np(zs)\n",
    "xs = (rng.uniform(size=means.shape) < means) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "im_grid = np.zeros((280, 280))\n",
    "for i, mean in enumerate(means[:100]):\n",
    "    row = i % 10\n",
    "    col = i // 10\n",
    "    im_grid[row * 28 : (row + 1) * 28, col * 28 : (col + 1) * 28] = (\n",
    "        mean.reshape(28, 28)\n",
    "    )\n",
    "ax.imshow(im_grid, cmap='Greys', interpolation='None')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate importance-weighted $\\log \\zeta$ approximations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "n_k = 100\n",
    "log_weights = []\n",
    "mean_z_gvn_x, std_z_gvn_x = mean_and_std_z_gvn_x_np(xs)\n",
    "for k in range(n_k):\n",
    "    n = rng.normal(size=mean_z_gvn_x.shape)\n",
    "    z = mean_z_gvn_x + std_z_gvn_x * n\n",
    "    log_weights.append(\n",
    "        log_prob_x_and_z_np(xs, z) - \n",
    "        (-0.5 * (n**2).sum(-1) - 0.5 * z.shape[-1] * np.log(2 * np.pi) - \n",
    "         np.log(std_z_gvn_x).sum(-1))\n",
    "    )\n",
    "log_weights = np.array(log_weights)\n",
    "m = np.max(log_weights, 0)\n",
    "log_zeta = np.log(np.exp(log_weights - m[None, :]).mean(0)) + m\n",
    "log_zeta_calc_time = time.time() - start_time\n",
    "print(log_zeta.mean(), log_zeta_calc_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create repeated model parameters / samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_zeta_rep = tt.constant(log_zeta.repeat(n_reps), 'log_zeta', 1, th.config.floatX) \n",
    "zs_rep = zs.repeat(n_reps, 0)\n",
    "xs_rep = tt.constant(\n",
    "    xs.repeat(n_reps, 0), 'x', 2, th.config.floatX)\n",
    "mean_z_gvn_x_rep = tt.constant(\n",
    "    mean_z_gvn_x.repeat(n_reps, 0), 'mean_z_gvn_x', 2, th.config.floatX)\n",
    "std_z_gvn_x_rep = tt.constant(\n",
    "    std_z_gvn_x.repeat(n_reps, 0), 'std_z_gvn_x', 2, th.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and AIS sampler objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_linearity_map = {\n",
    "    'nnet.Tanh': tt.tanh,\n",
    "    'nnet.Sigmoid': tt.nnet.sigmoid,\n",
    "    'nnet.Exp': tt.exp\n",
    "}\n",
    "non_linearities = [non_linearity_map[name] for name in decoder['layers'] if name != 'nnet.Linear']\n",
    "weights = [tt.constant(decoder['W' + str(i * 2)], 'dec_W' + str(i), 2, th.config.floatX) for i in range(3)]\n",
    "biases = [tt.constant(decoder['b' + str(i * 2)], 'dec_b' + str(i), 2, th.config.floatX) for i in range(3)]\n",
    "phi_func = PhiFunc(xs_rep, weights, biases, non_linearities, log_zeta_rep)\n",
    "psi_func = PsiFunc(mean_z_gvn_x_rep, std_z_gvn_x_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_sampler = disc_temp.AnnealedImportanceSampler(\n",
    "   rand.MRG_RandomStreams(seed), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tt.scalar('dt')\n",
    "hmc_params = {\n",
    "    'dt': dt,\n",
    "    'n_step': 10,\n",
    "    'mom_resample_coeff': 1.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = tt.matrix('pos')\n",
    "inv_temps= tt.vector('inv_temp_sched')\n",
    "pos_samples, log_weights, accepts, updates = ais_sampler.run(\n",
    "    pos, None, inv_temps, phi_func, psi_func, hmc_params\n",
    ")\n",
    "ais_run = th.function(\n",
    "    [pos, inv_temps, dt],\n",
    "    [pos_samples, log_weights, accepts],\n",
    "    updates=updates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIS settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_temps = 10000\n",
    "temp_scale = 4.\n",
    "dt = 0.08\n",
    "inv_temp_sched = sigmoidal_schedule(num_temps, temp_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Forward AIS run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_ais_start_time = time.time()\n",
    "pos_init = rng.normal(size=zs_rep.shape) * std_z_gvn_x_rep.value + mean_z_gvn_x_rep.value\n",
    "pos_samples, log_weights, accepts = ais_run(\n",
    "    pos_init.astype(th.config.floatX), inv_temp_sched.astype(th.config.floatX), dt)\n",
    "forward_ais_time = time.time() - forward_ais_start_time\n",
    "print(accepts.mean(), forward_ais_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse AIS run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_ais_start_time = time.time()\n",
    "rev_pos_samples, rev_log_weights, rev_accepts = ais_run(\n",
    "    zs_rep.astype(th.config.floatX), inv_temp_sched[::-1].astype(th.config.floatX), dt)\n",
    "reverse_ais_time = time.time() - reverse_ais_start_time\n",
    "print(rev_accepts.mean(), reverse_ais_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate stochastic lower and upper bounds on $\\mathbb{P}[\\mathbf{x} = \\boldsymbol{x}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_norm_approx = log_zeta.mean()\n",
    "log_norm_lower = log_norm_approx + np.log(np.exp(log_weights.reshape((-1, n_reps))).mean(-1)).mean(0)\n",
    "log_norm_upper = log_norm_approx + np.log(np.exp(-rev_log_weights.reshape((-1, n_reps))).mean(-1)).mean(0)\n",
    "print(log_norm_approx, log_norm_lower, log_norm_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez(\n",
    "    os.path.join(model_dir, 'joint-sample-and-log-norm-bounds.npz'),\n",
    "    xs=xs,\n",
    "    zs=zs,\n",
    "    seed=seed,\n",
    "    fwd_log_weights=log_weights,\n",
    "    rev_log_weights=rev_log_weights,\n",
    "    log_zeta=log_zeta,\n",
    "    log_norm_approx=log_norm_approx,\n",
    "    log_norm_lower=log_norm_lower,\n",
    "    log_norm_upper=log_norm_upper,\n",
    "    reverse_ais_time=reverse_ais_time,\n",
    "    forward_ais_time=forward_ais_time,\n",
    "    log_zeta_calc_time=log_zeta_calc_time,\n",
    "    mean_z_gvn_x=mean_z_gvn_x,\n",
    "    std_z_gvn_x=std_z_gvn_x,\n",
    "    mean_x_gvn_z=means\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
